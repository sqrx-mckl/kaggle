{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tutorial link](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import tensorflow.keras as keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                   text  label\n0     a stirring , funny and finally transporting re...      1\n1     apparently reassembled from the cutting room f...      0\n2     they presume their audience wo n't sit still f...      0\n3     this is a visually stunning rumination on love...      1\n4     jonathan parker 's bartleby should have been t...      1\n...                                                 ...    ...\n6915  painful , horrifying and oppressively tragic ,...      1\n6916  take care is nicely performed by a quintet of ...      0\n6917  the script covers huge , heavy topics in a bla...      0\n6918  a seriously bad film with seriously warped log...      0\n6919  a deliciously nonsensical comedy about a city ...      1\n\n[6920 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a stirring , funny and finally transporting re...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>apparently reassembled from the cutting room f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>they presume their audience wo n't sit still f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this is a visually stunning rumination on love...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>jonathan parker 's bartleby should have been t...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6915</th>\n      <td>painful , horrifying and oppressively tragic ,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6916</th>\n      <td>take care is nicely performed by a quintet of ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6917</th>\n      <td>the script covers huge , heavy topics in a bla...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6918</th>\n      <td>a seriously bad film with seriously warped log...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6919</th>\n      <td>a deliciously nonsensical comedy about a city ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6920 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', names=['text', 'label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 6920/6920 [00:04<00:00, 1696.75it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       [101, 1037, 18385, 1010, 6057, 1998, 2633, 182...\n1       [101, 4593, 2128, 27241, 23931, 2013, 1996, 62...\n2       [101, 2027, 3653, 23545, 2037, 4378, 24185, 10...\n3       [101, 2023, 2003, 1037, 17453, 14726, 19379, 1...\n4       [101, 5655, 6262, 1005, 1055, 12075, 2571, 376...\n                              ...                        \n6915    [101, 9145, 1010, 7570, 18752, 14116, 1998, 28...\n6916    [101, 2202, 2729, 2003, 19957, 2864, 2011, 103...\n6917    [101, 1996, 5896, 4472, 4121, 1010, 3082, 7832...\n6918    [101, 1037, 5667, 2919, 2143, 2007, 5667, 2561...\n6919    [101, 1037, 12090, 2135, 2512, 5054, 19570, 23...\nName: token, Length: 6920, dtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df['token'] = df['text'].progress_apply(\n",
    "    lambda x: tokenizer.encode(\n",
    "        str(x),\n",
    "        add_special_tokens=True\n",
    "    )\n",
    ")\n",
    "df['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[101,\n 1037,\n 18385,\n 1010,\n 6057,\n 1998,\n 2633,\n 18276,\n 2128,\n 16603,\n 1997,\n 5053,\n 1998,\n 1996,\n 6841,\n 1998,\n 5687,\n 5469,\n 3152,\n 102]"
     },
     "metadata": {},
     "execution_count": 6
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "67"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df['token'][0]\n",
    "MAX_LEN = df['token'].map(lambda x: len(x)).max()\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pad manually because \"encode_plus()\" has issue with the different layers:\n",
    "* it creates indeed an attention layer and can pad (which is good)\n",
    "* creates an error with the type layer (which is an inconsistency issue in the package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       67\n1       67\n2       67\n3       67\n4       67\n        ..\n6915    67\n6916    67\n6917    67\n6918    67\n6919    67\nName: token, Length: 6920, dtype: int64"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df['token'] = df['token'].map(\n",
    "    lambda x: np.pad(x, (0,MAX_LEN-len(x)), constant_values=0)\n",
    ")\n",
    "df['token'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df['attention'] = df['token'].map(\n",
    "    lambda x: x != 0\n",
    ")\n",
    "df['attention'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[  101,  1037, 18385, ...,     0,     0,     0],\n       [  101,  4593,  2128, ...,     0,     0,     0],\n       [  101,  2027,  3653, ...,     0,     0,     0],\n       ...,\n       [  101,  1996,  5896, ...,     0,     0,     0],\n       [  101,  1037,  5667, ...,     0,     0,     0],\n       [  101,  1037, 12090, ...,     0,     0,     0]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "np.vstack(df['token'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was used when I did not needed a batch (did not overflow RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(TensorShape([6920, 67]), TensorShape([6920, 67]))"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "from tensorflow import constant\n",
    "token = constant(np.vstack(df['token'].to_numpy()))\n",
    "attention = constant(np.vstack(df['attention'].to_numpy()))\n",
    "\n",
    "token.shape, attention.shape\n",
    "# \n",
    "# hidden_states = model(token, attention_mask = attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a batch with tf.data.Dataset to not overflow RAM and learn about batch dataset with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "139it [05:53,  2.54s/it]\n"
    }
   ],
   "source": [
    "from tensorflow import concat\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "data = Dataset.zip((\n",
    "    Dataset.from_tensor_slices(np.vstack(df['token'].to_numpy())),\n",
    "    Dataset.from_tensor_slices(np.vstack(df['attention'].to_numpy()))\n",
    "))\n",
    "\n",
    "hidden_states = None\n",
    "for batch in tqdm(data.batch(BATCH_SIZE)):\n",
    "    t = model(batch[0], attention_mask=batch[1])[0]\n",
    "    if hidden_states is None:\n",
    "        hidden_states = t\n",
    "    else:\n",
    "        hidden_states = concat([hidden_states, t], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TensorShape([6920, 67, 768])"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(6920, 768)"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "features = hidden_states[:,0,:].numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, df['label'].to_numpy())\n",
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OneClassSVM()"
     },
     "metadata": {},
     "execution_count": 47
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.500578034682081"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "svm = OneClassSVM()\n",
    "svm.fit(x_train, y_train)\n",
    "accuracy_score(y_test, svm.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "metadata": {},
     "execution_count": 48
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8410404624277457"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier()"
     },
     "metadata": {},
     "execution_count": 49
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7936416184971098"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit0c4c6548c9c84e2fae654109a0bf4cdb",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}